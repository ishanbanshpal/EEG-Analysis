{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e44a1a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features:\n",
      "Index(['Slope_Channel_3', 'Slope_Channel_6', 'Slope_Channel_10',\n",
      "       'Slope_Channel_11', 'Slope_Channel_12', 'Slope_Channel_13',\n",
      "       'ITF_Channel_0', 'ITF_Channel_1', 'ITF_Channel_2', 'ITF_Channel_3',\n",
      "       'ITF_Channel_4', 'ITF_Channel_5', 'ITF_Channel_6', 'ITF_Channel_7',\n",
      "       'ITF_Channel_8', 'ITF_Channel_9', 'ITF_Channel_10', 'ITF_Channel_11',\n",
      "       'ITF_Channel_12'],\n",
      "      dtype='object')\n",
      "Accuracy for Task Classification with PCA and Selected Features using SVM: 0.8333333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89         4\n",
      "           1       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.83         6\n",
      "   macro avg       0.90      0.75      0.78         6\n",
      "weighted avg       0.87      0.83      0.81         6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('Control Med&Rest0311.csv')\n",
    "\n",
    "# Encode the 'Group' column\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Encode the 'Task' column\n",
    "data['Task'] = label_encoder.fit_transform(data['Task'])\n",
    "\n",
    "\n",
    "\n",
    "# Define your feature columns (X) and target columns (y_group and y_task)\n",
    "X = data[[\"Slope_Channel_0\",\"Slope_Channel_1\",\"Slope_Channel_2\",\"Slope_Channel_3\",\"Slope_Channel_4\",\"Slope_Channel_5\",\"Slope_Channel_6\",\"Slope_Channel_7\",\"Slope_Channel_8\",\"Slope_Channel_9\",\"Slope_Channel_10\",\"Slope_Channel_11\",\"Slope_Channel_12\",\"Slope_Channel_13\",\"ITF_Channel_0\",\"ITF_Channel_1\",\"ITF_Channel_2\",\"ITF_Channel_3\",\"ITF_Channel_4\",\"ITF_Channel_5\",\"ITF_Channel_6\",\"ITF_Channel_7\",\"ITF_Channel_8\",\"ITF_Channel_9\",\"ITF_Channel_10\",\"ITF_Channel_11\",\"ITF_Channel_12\",\"ITF_Channel_13\",\"ITP_Channel_0\",\"ITP_Channel_1\",\"ITP_Channel_2\",\"ITP_Channel_3\",\"ITP_Channel_4\",\"ITP_Channel_5\",\"ITP_Channel_6\",\"ITP_Channel_7\",\"ITP_Channel_8\",\"ITP_Channel_9\",\"ITP_Channel_10\",\"ITP_Channel_11\",\"ITP_Channel_12\",\"ITP_Channel_13\",\"IAF_Channel_0\",\"IAF_Channel_1\",\"IAF_Channel_2\",\"IAF_Channel_3\",\"IAF_Channel_4\",\"IAF_Channel_5\",\"IAF_Channel_6\",\"IAF_Channel_7\",\"IAF_Channel_8\",\"IAF_Channel_9\",\"IAF_Channel_10\",\"IAF_Channel_11\",\"IAF_Channel_12\",\"IAF_Channel_13\",\"IAP_Channel_0\",\"IAP_Channel_1\",\"IAP_Channel_2\",\"IAP_Channel_3\",\"IAP_Channel_4\",\"IAP_Channel_5\",\"IAP_Channel_6\",\"IAP_Channel_7\",\"IAP_Channel_8\",\"IAP_Channel_9\",\"IAP_Channel_10\",\"IAP_Channel_11\",\"IAP_Channel_12\",\"IAP_Channel_13\",\"IBF_Channel_0\",\"IBF_Channel_1\",\"IBF_Channel_2\",\"IBF_Channel_3\",\"IBF_Channel_4\",\"IBF_Channel_5\",\"IBF_Channel_6\",\"IBF_Channel_7\",\"IBF_Channel_8\",\"IBF_Channel_9\",\"IBF_Channel_10\",\"IBF_Channel_11\",\"IBF_Channel_12\",\"IBF_Channel_13\",\"IBP_Channel_0\",\"IBP_Channel_1\",\"IBP_Channel_2\",\"IBP_Channel_3\",\"IBP_Channel_4\",\"IBP_Channel_5\",\"IBP_Channel_6\",\"IBP_Channel_7\",\"IBP_Channel_8\",\"IBP_Channel_9\",\"IBP_Channel_10\",\"IBP_Channel_11\",\"IBP_Channel_12\",\"IBP_Channel_13\",\"Mean_PSD_Channel_Alpha_0\",\"Mean_PSD_Channel_Alpha_1\",\"Mean_PSD_Channel_Alpha_2\",\"Mean_PSD_Channel_Alpha_3\",\"Mean_PSD_Channel_Alpha_4\",\"Mean_PSD_Channel_Alpha_5\",\"Mean_PSD_Channel_Alpha_6\",\"Mean_PSD_Channel_Alpha_7\",\"Mean_PSD_Channel_Alpha_8\",\"Mean_PSD_Channel_Alpha_9\",\"Mean_PSD_Channel_Alpha_10\",\"Mean_PSD_Channel_Alpha_11\",\"Mean_PSD_Channel_Alpha_12\",\"Mean_PSD_Channel_Alpha_13\",\"Mean_PSD_Channel_Beta_0\",\"Mean_PSD_Channel_Beta_1\",\"Mean_PSD_Channel_Beta_2\",\"Mean_PSD_Channel_Beta_3\",\"Mean_PSD_Channel_Beta_4\",\"Mean_PSD_Channel_Beta_5\",\"Mean_PSD_Channel_Beta_6\",\"Mean_PSD_Channel_Beta_7\",\"Mean_PSD_Channel_Beta_8\",\"Mean_PSD_Channel_Beta_9\",\"Mean_PSD_Channel_Beta_10\",\"Mean_PSD_Channel_Beta_11\",\"Mean_PSD_Channel_Beta_12\",\"Mean_PSD_Channel_Beta_13\"]]\n",
    "\n",
    "y_task = data['Task']\n",
    "\n",
    "# Split the data into training and testing sets for Task classification\n",
    "X_train_task, X_test_task, y_train_task, y_test_task = train_test_split(X, y_task, test_size=0.1, random_state=21)\n",
    "\n",
    "# Standardize the features for Task classification\n",
    "scaler_task = StandardScaler()\n",
    "X_train_task = scaler_task.fit_transform(X_train_task)\n",
    "X_test_task = scaler_task.transform(X_test_task)\n",
    "\n",
    "# Apply PCA for dimensionality reduction for Task classification\n",
    "n_components = 27\n",
    "pca = PCA(n_components=n_components)\n",
    "X_train_task_pca = pca.fit_transform(X_train_task)\n",
    "X_test_task_pca = pca.transform(X_test_task)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Feature selection using SelectKBest with mutual information score on PCA components\n",
    "k_best = SelectKBest(mutual_info_classif, k=19)\n",
    "X_train_task_pca_best = k_best.fit_transform(X_train_task_pca, y_train_task)\n",
    "X_test_task_pca_best = k_best.transform(X_test_task_pca)\n",
    "\n",
    "\n",
    "\n",
    "# Get the indices of the selected features\n",
    "selected_feature_indices = k_best.get_support(indices=True)\n",
    "\n",
    "# Get the names of the selected features\n",
    "selected_feature_names = X.columns[selected_feature_indices]\n",
    "\n",
    "# Print the names of the selected features\n",
    "print(\"Selected Features:\")\n",
    "print(selected_feature_names)\n",
    "      \n",
    "      \n",
    "# Define the SVM model for Task classification with PCA and selected features\n",
    "svm_model = SVC(kernel='linear', C=0.5, random_state=30)\n",
    "svm_model.fit(X_train_task_pca_best, y_train_task)\n",
    "\n",
    "# Predict the labels on the test data for Task classification\n",
    "y_pred_task_pca_best = svm_model.predict(X_test_task_pca_best)\n",
    "\n",
    "# Calculate accuracy and classification report for Task classification\n",
    "accuracy_task_pca_best = accuracy_score(y_test_task, y_pred_task_pca_best)\n",
    "report_task_pca_best = classification_report(y_test_task, y_pred_task_pca_best)\n",
    "\n",
    "print(f'Accuracy for Task Classification with PCA and Selected Features using SVM: {accuracy_task_pca_best}')\n",
    "print(report_task_pca_best)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5a1c38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[4 0]\n",
      " [1 1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "confusion_matrix_task = confusion_matrix(y_test_task, y_pred_task_pca_best)\n",
    "\n",
    "# Display the coanfusion matriacx\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix_task)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3c1fcc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier:\n",
      "Accuracy: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         4\n",
      "           1       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00         6\n",
      "   macro avg       1.00      1.00      1.00         6\n",
      "weighted avg       1.00      1.00      1.00         6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create a Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "rf_classifier.fit(X_train_task_pca_best, y_train_task)\n",
    "\n",
    "# Predict the labels on the test data\n",
    "y_pred_rf = rf_classifier.predict(X_test_task_pca_best)\n",
    "\n",
    "# Evaluate the Random Forest classifier\n",
    "accuracy_rf = accuracy_score(y_test_task, y_pred_rf)\n",
    "report_rf = classification_report(y_test_task, y_pred_rf)\n",
    "\n",
    "print(\"Random Forest Classifier:\")\n",
    "print(f'Accuracy: {accuracy_rf}')\n",
    "print(report_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b440c2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier:\n",
      "Accuracy: 0.6666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75         4\n",
      "           1       0.50      0.50      0.50         2\n",
      "\n",
      "    accuracy                           0.67         6\n",
      "   macro avg       0.62      0.62      0.62         6\n",
      "weighted avg       0.67      0.67      0.67         6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Create a Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "dt_classifier.fit(X_train_task_pca_best, y_train_task)\n",
    "\n",
    "# Predict the labels on the test data\n",
    "y_pred_dt = dt_classifier.predict(X_test_task_pca_best)\n",
    "\n",
    "# Evaluate the Decision Tree classifier\n",
    "accuracy_dt = accuracy_score(y_test_task, y_pred_dt)\n",
    "report_dt = classification_report(y_test_task, y_pred_dt)\n",
    "\n",
    "print(\"Decision Tree Classifier:\")\n",
    "print(f'Accuracy: {accuracy_dt}')\n",
    "print(report_dt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90192433",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.8212 - accuracy: 0.5192\n",
      "Epoch 2/25\n",
      "2/2 [==============================] - 0s 0s/step - loss: 0.7549 - accuracy: 0.5192\n",
      "Epoch 3/25\n",
      "2/2 [==============================] - 0s 0s/step - loss: 0.7118 - accuracy: 0.5192\n",
      "Epoch 4/25\n",
      "2/2 [==============================] - 0s 0s/step - loss: 0.6742 - accuracy: 0.5577\n",
      "Epoch 5/25\n",
      "2/2 [==============================] - 0s 413us/step - loss: 0.6496 - accuracy: 0.5385\n",
      "Epoch 6/25\n",
      "2/2 [==============================] - 0s 0s/step - loss: 0.6226 - accuracy: 0.6154\n",
      "Epoch 7/25\n",
      "2/2 [==============================] - 0s 0s/step - loss: 0.6051 - accuracy: 0.6923\n",
      "Epoch 8/25\n",
      "2/2 [==============================] - 0s 0s/step - loss: 0.5918 - accuracy: 0.7308\n",
      "Epoch 9/25\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5755 - accuracy: 0.7308\n",
      "Epoch 10/25\n",
      "2/2 [==============================] - 0s 0s/step - loss: 0.5632 - accuracy: 0.7692\n",
      "Epoch 11/25\n",
      "2/2 [==============================] - 0s 0s/step - loss: 0.5486 - accuracy: 0.7692\n",
      "Epoch 12/25\n",
      "2/2 [==============================] - 0s 0s/step - loss: 0.5335 - accuracy: 0.8077\n",
      "Epoch 13/25\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5193 - accuracy: 0.8462\n",
      "Epoch 14/25\n",
      "2/2 [==============================] - 0s 0s/step - loss: 0.5045 - accuracy: 0.8462\n",
      "Epoch 15/25\n",
      "2/2 [==============================] - 0s 0s/step - loss: 0.4925 - accuracy: 0.8654\n",
      "Epoch 16/25\n",
      "2/2 [==============================] - 0s 0s/step - loss: 0.4795 - accuracy: 0.9038\n",
      "Epoch 17/25\n",
      "2/2 [==============================] - 0s 0s/step - loss: 0.4675 - accuracy: 0.9231\n",
      "Epoch 18/25\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.4560 - accuracy: 0.9423\n",
      "Epoch 19/25\n",
      "2/2 [==============================] - 0s 0s/step - loss: 0.4448 - accuracy: 0.9423\n",
      "Epoch 20/25\n",
      "2/2 [==============================] - 0s 0s/step - loss: 0.4338 - accuracy: 0.9423\n",
      "Epoch 21/25\n",
      "2/2 [==============================] - 0s 0s/step - loss: 0.4235 - accuracy: 0.9423\n",
      "Epoch 22/25\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4137 - accuracy: 0.9423\n",
      "Epoch 23/25\n",
      "2/2 [==============================] - 0s 0s/step - loss: 0.4034 - accuracy: 0.9423\n",
      "Epoch 24/25\n",
      "2/2 [==============================] - 0s 0s/step - loss: 0.3942 - accuracy: 0.9423\n",
      "Epoch 25/25\n",
      "2/2 [==============================] - 0s 0s/step - loss: 0.3847 - accuracy: 0.9423\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "Neural Network (Deep Learning) Classifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.75      0.86         4\n",
      "           1       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.83         6\n",
      "   macro avg       0.83      0.88      0.83         6\n",
      "weighted avg       0.89      0.83      0.84         6\n",
      "\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.4365 - accuracy: 0.8333\n",
      "Accuracy: 0.8333333134651184\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Create a simple neural network model\n",
    "model = Sequential()\n",
    "model.add(Dense(units=64, input_dim=X_train_task_pca_best.shape[1], activation='relu'))\n",
    "model.add(Dense(units=32, activation='relu'))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.001), metrics=['accuracy'])\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train_task_pca_best, y_train_task, epochs=25, batch_size=32)\n",
    "\n",
    "# Predict the labels on the test data\n",
    "y_pred_nn = model.predict(X_test_task_pca_best)\n",
    "y_pred_nn = (y_pred_nn > 0.5).astype(int)  # Convert probabilities to class labels\n",
    "\n",
    "# Print the classification report\n",
    "report_nn = classification_report(y_test_task, y_pred_nn)\n",
    "print(\"Neural Network (Deep Learning) Classifier:\")\n",
    "print(report_nn)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "_, accuracy_nn = model.evaluate(X_test_task_pca_best, y_test_task)\n",
    "print(f'Accuracy: {accuracy_nn}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e773e0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa505852",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29905dd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a837f5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef946e8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4567ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5015c10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
